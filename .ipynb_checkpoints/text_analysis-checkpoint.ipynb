{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d380c851-0cdc-4af6-8569-c3a01665b5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sumy in /opt/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (2.32.2)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from sumy) (3.8.1)\n",
      "Requirement already satisfied: chardet in /opt/anaconda3/lib/python3.12/site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from breadability>=0.1.20->sumy) (5.2.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk>=3.0.2->sumy) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.7.0->sumy) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas nltk gensim sumy tqdm\n",
    "# !pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59faac89-c423-4f4a-a841-680e60c27d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /Users/joshawa-\n",
      "[nltk_data]     ao/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6a930d2-1965-479f-8c7c-7d981fac8f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step into the spotlight: Apply to speak at Tec...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-24T08:17:30-07:00</td>\n",
       "      <td>https://techcrunch.com/2025/03/24/step-into-th...</td>\n",
       "      <td>Calling all tech innovators, startup fanatics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TechCrunch Disrupt 2025 tickets now on sale: L...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-01-24T11:39:20-08:00</td>\n",
       "      <td>https://techcrunch.com/2025/01/24/techcrunch-d...</td>\n",
       "      <td>We’re kicking things off earlier than ever!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Tesla Takedown’ protesters are planning a glo...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-28T14:47:15-07:00</td>\n",
       "      <td>https://techcrunch.com/2025/03/28/tesla-takedo...</td>\n",
       "      <td>“Tesla Takedown” organizers have promised thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google rolls out new vacation-planning feature...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-27T06:00:00-07:00</td>\n",
       "      <td>https://techcrunch.com/2025/03/27/google-rolls...</td>\n",
       "      <td>Google is rolling out a slew of new features —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenAI’s viral Studio Ghibli moment highlights...</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-03-26T16:23:09-07:00</td>\n",
       "      <td>https://techcrunch.com/2025/03/26/openais-vira...</td>\n",
       "      <td>It’s only been a day since  , and social media...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title author  \\\n",
       "0  Step into the spotlight: Apply to speak at Tec...   None   \n",
       "1  TechCrunch Disrupt 2025 tickets now on sale: L...   None   \n",
       "2  ‘Tesla Takedown’ protesters are planning a glo...   None   \n",
       "3  Google rolls out new vacation-planning feature...   None   \n",
       "4  OpenAI’s viral Studio Ghibli moment highlights...   None   \n",
       "\n",
       "                        date  \\\n",
       "0  2025-03-24T08:17:30-07:00   \n",
       "1  2025-01-24T11:39:20-08:00   \n",
       "2  2025-03-28T14:47:15-07:00   \n",
       "3  2025-03-27T06:00:00-07:00   \n",
       "4  2025-03-26T16:23:09-07:00   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://techcrunch.com/2025/03/24/step-into-th...   \n",
       "1  https://techcrunch.com/2025/01/24/techcrunch-d...   \n",
       "2  https://techcrunch.com/2025/03/28/tesla-takedo...   \n",
       "3  https://techcrunch.com/2025/03/27/google-rolls...   \n",
       "4  https://techcrunch.com/2025/03/26/openais-vira...   \n",
       "\n",
       "                                             content  \n",
       "0  Calling all tech innovators, startup fanatics,...  \n",
       "1  We’re kicking things off earlier than ever!   ...  \n",
       "2  “Tesla Takedown” organizers have promised thei...  \n",
       "3  Google is rolling out a slew of new features —...  \n",
       "4  It’s only been a day since  , and social media...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"part_1/disrupt_articles.json\", \"r\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "segments = raw.split(\"][\")  # split where JSON arrays are glued together\n",
    "cleaned = []\n",
    "\n",
    "for i, s in enumerate(segments):\n",
    "    if i == 0:\n",
    "        s = s + \"]\"\n",
    "    elif i == len(segments) - 1:\n",
    "        s = \"[\" + s\n",
    "    else:\n",
    "        s = \"[\" + s + \"]\"\n",
    "\n",
    "    try:\n",
    "        cleaned.extend(json.loads(s))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Skipping bad segment: {e}\")\n",
    "\n",
    "df = pd.DataFrame(cleaned)\n",
    "df = df[df['content'].str.strip() != \"\"]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5df2bc39-3679-4cc0-bf7a-fdb8faf3cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/joshawa-\n",
      "[nltk_data]     ao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /Users/joshawa-\n",
      "[nltk_data]     ao/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c217a15-7145-41fa-85e8-b3689d024652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "summarizer = TextRankSummarizer()\n",
    "tokenizer = Tokenizer(\"english\")\n",
    "keywords = ['disrupt', 'startup', 'tech', 'funding', 'ai', 'innovation', 'launch']\n",
    "\n",
    "# Helper functions\n",
    "def summarize(text):\n",
    "    try:\n",
    "        parser = PlaintextParser.from_string(text, tokenizer)\n",
    "        summary = summarizer(parser.document, 2)\n",
    "        return \" \".join(str(s) for s in summary)\n",
    "    except:\n",
    "        return text[:250] + \"...\"\n",
    "\n",
    "def importance_score(text):\n",
    "    text_lower = text.lower()\n",
    "    return sum(text_lower.count(word) for word in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93d2ddcc-206c-4c35-8b36-32b003c555f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Importance Score</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step into the spotlight: Apply to speak at Tec...</td>\n",
       "      <td>We’re curating a diverse group of industry exp...</td>\n",
       "      <td>13</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TechCrunch Disrupt 2025 tickets now on sale: L...</td>\n",
       "      <td>From now through January 31, take advantage of...</td>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Tesla Takedown’ protesters are planning a glo...</td>\n",
       "      <td>“The reason that [Musk] is in the position tha...</td>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google rolls out new vacation-planning feature...</td>\n",
       "      <td>Starting this week, users can search for somet...</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenAI’s viral Studio Ghibli moment highlights...</td>\n",
       "      <td>In a statement to TechCrunch, an OpenAI spokes...</td>\n",
       "      <td>40</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Step into the spotlight: Apply to speak at Tec...   \n",
       "1  TechCrunch Disrupt 2025 tickets now on sale: L...   \n",
       "2  ‘Tesla Takedown’ protesters are planning a glo...   \n",
       "3  Google rolls out new vacation-planning feature...   \n",
       "4  OpenAI’s viral Studio Ghibli moment highlights...   \n",
       "\n",
       "                                             Summary  Importance Score  \\\n",
       "0  We’re curating a diverse group of industry exp...                13   \n",
       "1  From now through January 31, take advantage of...                19   \n",
       "2  “The reason that [Musk] is in the position tha...                14   \n",
       "3  Starting this week, users can search for somet...                10   \n",
       "4  In a statement to TechCrunch, an OpenAI spokes...                40   \n",
       "\n",
       "  Direction  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  positive  \n",
       "4  positive  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    content = row['content']\n",
    "    summary = summarize(content)\n",
    "    sentiment = sia.polarity_scores(content)\n",
    "    direction = \"positive\" if sentiment['compound'] > 0 else \"negative\"\n",
    "    score = importance_score(content)\n",
    "\n",
    "    results.append({\n",
    "        \"Title\": row['title'],\n",
    "        \"Summary\": summary,\n",
    "        \"Importance Score\": score,\n",
    "        \"Direction\": direction\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(results)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726dbd0-5c00-4469-9a3a-11f23b197227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
